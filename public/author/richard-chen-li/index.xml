<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Richard Chen Li | YE JIA</title>
    <link>http://localhost:59545/author/richard-chen-li/</link>
      <atom:link href="http://localhost:59545/author/richard-chen-li/index.xml" rel="self" type="application/rss+xml" />
    <description>Richard Chen Li</description>
    <generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Sat, 16 Mar 2024 00:00:00 +0000</lastBuildDate>
    <image>
      <url>http://localhost:59545/media/icon_hu3778854248838762986.png</url>
      <title>Richard Chen Li</title>
      <link>http://localhost:59545/author/richard-chen-li/</link>
    </image>
    
    <item>
      <title>illumotion: An Optical-illusion-based VR Locomotion Technique for Long-Distance 3D Movement</title>
      <link>http://localhost:59545/publication/sin-2024-illumotion/</link>
      <pubDate>Sat, 16 Mar 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:59545/publication/sin-2024-illumotion/</guid>
      <description>&lt;h3 id=&#34;abstract&#34;&gt;Abstract&lt;/h3&gt;
&lt;p&gt;Locomotion has a marked impact on user experience in VR, but currently, common to-go techniques such as steering and teleportation have their limitations. Particularly, steering is prone to cybersickness, while teleportation trades presence for mitigating cybersickness. Inspired by how we manipulate a picture on a mobile phone, we propose illumotion, an optical-illusion-based method that, we believe, can provide an alternative to these two typical techniques. Instead of zooming in a picture by pinching two ﬁngers, we can move forward by “zooming” toward part of the 3D virtual scene with pinched hands. Not only is the proposed technique easy to use, it also seems to minimize cybersickness to some degree.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;illumotion&lt;/em&gt; relies on the manipulation of optics; as such, it requires solving motion parameters in screen space and a model of how we perceive depth. To evaluate it, a comprehensive user study with 66 users was conducted. Results show that, compared with either teleportation, steering or both, illumotion has better performance, presence, usability, user experience and cybersickness alleviation. We believe the result is a clear indication that our novel opticallydriven method is a promising candidate for generalized locomotion.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>From classroom to metaverse: a study on gamified constructivist teaching in higher education</title>
      <link>http://localhost:59545/publication/ng-2023-classroom/</link>
      <pubDate>Sun, 01 Jan 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:59545/publication/ng-2023-classroom/</guid>
      <description>&lt;h3 id=&#34;abstract&#34;&gt;Abstract&lt;/h3&gt;
&lt;p&gt;In the rapidly evolving educational landscape, the integration of metaverse and gamiﬁcation is emerging as a revolutionary approach. This paper presents the Gamiﬁed Constructivist Teaching in the Metaverse (GCTM) framework, aiming to enhance engagement and satisfaction in the computer science education domain. Implemented in two engineering classes using the metaverse platform, the GCTM model, with its unique combination of game world design, rule design, roleplay, mission assignments, and evaluation, demonstrated promising results in enhancing student-lecturer interactions. Feedback indicated a stronger sense of belonging among students in the virtual environment compared to conventional platforms like ZOOM or MS Teams. The ﬁndings underscore the potential of GCTM in transforming the educational experience, suggesting a signiﬁcant stride towards a more interactive and learner-centric approach in the metaverse-driven educational era.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Towards an edu-metaverse of knowledge: Immersive exploration of university courses</title>
      <link>http://localhost:59545/publication/sin-2023-towards/</link>
      <pubDate>Sun, 01 Jan 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:59545/publication/sin-2023-towards/</guid>
      <description>&lt;h3 id=&#34;abstract&#34;&gt;Abstract&lt;/h3&gt;
&lt;p&gt;Metaverse, an alternative universe for play, work and interaction, has become a captivating topic for academia and industry in recent times. This opens the question on what a metaverse for education, or edu-metaverse, should look like. It is believed that this metaverse for learning should be grounded by a pedagogical theory. Particularly, we propose a constructivist metaverse learning theory with eight actionable principles to guide the edu-metaverse and its applications. With this metaverse learning theory, we further propose the framework for an edu-metaverse; it is essentially walkable yellow pages that connect knowledge. The core idea is to combine the structure of knowledge graphs and the immersion of virtual reality in order to facilitate association, exploration and engagement in learning. Our current prototype for this edu-metaverse vision, K-Cube VR, is also presented. We have tested K-Cube VR for the introduction of course topics to our students and the results indicate that our edu-metaverse framework benefits students by providing a focused environment and structured learning on the topics of a course, akin to a mind map. Overall, in this paper, we present an edu-metaverse design that is rooted in a constructivist pedagogy that already shows promising results from a pilot user study via our metaverse prototype.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
