<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Ye Jia | YE JIA</title>
    <link>http://localhost:59545/author/ye-jia/</link>
      <atom:link href="http://localhost:59545/author/ye-jia/index.xml" rel="self" type="application/rss+xml" />
    <description>Ye Jia</description>
    <generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Tue, 22 Jul 2025 00:00:00 +0000</lastBuildDate>
    <image>
      <url>http://localhost:59545/media/icon_hu3778854248838762986.png</url>
      <title>Ye Jia</title>
      <link>http://localhost:59545/author/ye-jia/</link>
    </image>
    
    <item>
      <title>To Be Determined</title>
      <link>http://localhost:59545/upcoming/jiaye-005/</link>
      <pubDate>Tue, 22 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:59545/upcoming/jiaye-005/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Submitted&lt;/strong&gt;: 28th Feb 2025&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>To Be Determined</title>
      <link>http://localhost:59545/upcoming/jiaye-002/</link>
      <pubDate>Wed, 01 Jan 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:59545/upcoming/jiaye-002/</guid>
      <description></description>
    </item>
    
    <item>
      <title>To Be Determined</title>
      <link>http://localhost:59545/upcoming/jiaye-003/</link>
      <pubDate>Wed, 01 Jan 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:59545/upcoming/jiaye-003/</guid>
      <description></description>
    </item>
    
    <item>
      <title>To Be Determined</title>
      <link>http://localhost:59545/upcoming/jiaye-004/</link>
      <pubDate>Wed, 01 Jan 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:59545/upcoming/jiaye-004/</guid>
      <description></description>
    </item>
    
    <item>
      <title>To Be Determined</title>
      <link>http://localhost:59545/upcoming/jiaye-006/</link>
      <pubDate>Wed, 01 Jan 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:59545/upcoming/jiaye-006/</guid>
      <description></description>
    </item>
    
    <item>
      <title>To Be Determined</title>
      <link>http://localhost:59545/upcoming/jiaye-007/</link>
      <pubDate>Wed, 01 Jan 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:59545/upcoming/jiaye-007/</guid>
      <description></description>
    </item>
    
    <item>
      <title>23rd International Conference on Web-based Learning</title>
      <link>http://localhost:59545/event/icwl_2024/</link>
      <pubDate>Wed, 18 Dec 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:59545/event/icwl_2024/</guid>
      <description>&lt;p&gt;Detailed 

&lt;div class=&#34;w-full h-auto aspect-video relative&#34;&gt;
  &lt;iframe src=&#34;//player.bilibili.com/player.html?bvid=BV1AAkqYREEX&amp;page=1&#34;
  allow=&#34;accelerometer; clipboard-write; encrypted-media; gyroscope; fullscreen; picture-in-picture;&#34;
  class=&#34;w-full h-full&#34;
  &gt;&lt;/iframe&gt;
&lt;/div&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Traceable teleportation: Improving spatial learning in virtual locomotion</title>
      <link>http://localhost:59545/publication/jia-2024-undo-redo/</link>
      <pubDate>Sat, 02 Nov 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:59545/publication/jia-2024-undo-redo/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;Submitted, 02 Jan 2024&lt;/li&gt;
&lt;li&gt;Revision 1, 18 Apr 2024&lt;/li&gt;
&lt;li&gt;Revision 2, 23 Sep 2024&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Accepted, 22 Oct 2024&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>2nd Annual IEEE International Conference on Metaverse Computing, Networking, and Applications</title>
      <link>http://localhost:59545/event/metacom_2024/</link>
      <pubDate>Mon, 12 Aug 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:59545/event/metacom_2024/</guid>
      <description>&lt;p&gt;Detailed 
&lt;/p&gt;











  





&lt;video controls  &gt;
  &lt;source src=&#34;https://kcube.comp.polyu.edu.hk/kcube/assets/avi/0080-conf/vid/0080-K-Cube-Conference-240813-MetaCom2024-JiaYe.mp4&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;

</description>
    </item>
    
    <item>
      <title>NivTA: Towards a Naturally Interactable Edu-Metaverse Teaching Assistant for CAVE</title>
      <link>http://localhost:59545/publication/jia-2024-niv-ta/</link>
      <pubDate>Mon, 12 Aug 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:59545/publication/jia-2024-niv-ta/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Knowledge-Graph-Driven Mind Mapping for Immersive Collaborative Learning: A Pilot Study in Edu-Metaverse</title>
      <link>http://localhost:59545/publication/jia-2024-knowledge/</link>
      <pubDate>Tue, 28 May 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:59545/publication/jia-2024-knowledge/</guid>
      <description>&lt;h3 id=&#34;abstract&#34;&gt;Abstract&lt;/h3&gt;
&lt;p&gt;One of the promises of edu-metaverse is its ability to provide a virtual environment that enables us to engage in learning activities that are similar to or on par with reality. The digital enhancements introduced in a virtual environment contribute to our increased expectations of novel learning experiences. However, despite its promising outcomes, there appears to be limited adoption of the edu-metaverse for practical learning at this time. We believe this can be attributed to the fact that there is a lack of investigation into learners’ behavior given a social learning environment. This lack of investigation is critical, as without behavioral insight, it hinders the development of education material and the direction of an edu-metaverse. Upon completing our work with the pilot user studies, we provide the following insights: 1) compared to Zoom, a typical video conferencing and remote collaboration platform, learners in the edu-metaverse demonstrate heightened involvement in learning activities, particularly when drawing mind mapping aided by the embedded knowledge graph, and this copresence signiﬁcantly boosts learner engagement and collaborative contribution to the learning tasks; and 2) the interaction and learning activity design within the edu-metaverse, especially concerning the use of MM.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>illumotion: An Optical-illusion-based VR Locomotion Technique for Long-Distance 3D Movement</title>
      <link>http://localhost:59545/publication/sin-2024-illumotion/</link>
      <pubDate>Sat, 16 Mar 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:59545/publication/sin-2024-illumotion/</guid>
      <description>&lt;h3 id=&#34;abstract&#34;&gt;Abstract&lt;/h3&gt;
&lt;p&gt;Locomotion has a marked impact on user experience in VR, but currently, common to-go techniques such as steering and teleportation have their limitations. Particularly, steering is prone to cybersickness, while teleportation trades presence for mitigating cybersickness. Inspired by how we manipulate a picture on a mobile phone, we propose illumotion, an optical-illusion-based method that, we believe, can provide an alternative to these two typical techniques. Instead of zooming in a picture by pinching two ﬁngers, we can move forward by “zooming” toward part of the 3D virtual scene with pinched hands. Not only is the proposed technique easy to use, it also seems to minimize cybersickness to some degree.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;illumotion&lt;/em&gt; relies on the manipulation of optics; as such, it requires solving motion parameters in screen space and a model of how we perceive depth. To evaluate it, a comprehensive user study with 66 users was conducted. Results show that, compared with either teleportation, steering or both, illumotion has better performance, presence, usability, user experience and cybersickness alleviation. We believe the result is a clear indication that our novel opticallydriven method is a promising candidate for generalized locomotion.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Towards Effective Collaborative Learning in Edu-Metaverse: A Study on Learners’ Anxiety, Perception, and Behaviour</title>
      <link>http://localhost:59545/upcoming/lu-2024-effective/</link>
      <pubDate>Tue, 09 Jan 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:59545/upcoming/lu-2024-effective/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;Submitted 15 Aug 2024&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Accepted&lt;/strong&gt;, 01 Sep 2024&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;Abstract&lt;/em&gt; In the evolving landscape of educational technology, Edu-
Metaversepresentsauniquetechnologicalplatformforcollaborativelearn-
ing (CL), which can be especially useful in distance learning settings. Re-
searchers have taken a keen interest in the potential of Edu-Metaverse
for enabling and improving CL; however, the effects of various factors
on CL behaviours and performance still need to be fully understood.
This study used a within-subjects design involving 32 participants (16
females and 16 males) to investigate how learners’ attributes and envi-
ronmental attributes affect CL in Edu-Metaverse. The participants were
randomly assigned to groups of four for a CL session in Edu-Metaverse.
The confirmatory factor analysis revealed that various behavioural met-
rics in Edu-Metaverse mediated the effects of trait anxiety and virtual
space satisfaction on CL performance; perceived understanding of mes-
sages, under the umbrella of social presence, also had a direct effect on
CL performance. These insights underscore the importance of optimising
interactive,perceptual,andsocialcomponentstomakeCLmoreeffective
in Edu-Metaverse.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>To Be Determined</title>
      <link>http://localhost:59545/upcoming/jiaye-001/</link>
      <pubDate>Mon, 01 Jan 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:59545/upcoming/jiaye-001/</guid>
      <description></description>
    </item>
    
    <item>
      <title>From classroom to metaverse: a study on gamified constructivist teaching in higher education</title>
      <link>http://localhost:59545/publication/ng-2023-classroom/</link>
      <pubDate>Sun, 01 Jan 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:59545/publication/ng-2023-classroom/</guid>
      <description>&lt;h3 id=&#34;abstract&#34;&gt;Abstract&lt;/h3&gt;
&lt;p&gt;In the rapidly evolving educational landscape, the integration of metaverse and gamiﬁcation is emerging as a revolutionary approach. This paper presents the Gamiﬁed Constructivist Teaching in the Metaverse (GCTM) framework, aiming to enhance engagement and satisfaction in the computer science education domain. Implemented in two engineering classes using the metaverse platform, the GCTM model, with its unique combination of game world design, rule design, roleplay, mission assignments, and evaluation, demonstrated promising results in enhancing student-lecturer interactions. Feedback indicated a stronger sense of belonging among students in the virtual environment compared to conventional platforms like ZOOM or MS Teams. The ﬁndings underscore the potential of GCTM in transforming the educational experience, suggesting a signiﬁcant stride towards a more interactive and learner-centric approach in the metaverse-driven educational era.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Signal-to-image: Rolling bearing fault diagnosis using ResNet family deep-learning models</title>
      <link>http://localhost:59545/publication/wu-2023-signal/</link>
      <pubDate>Sun, 01 Jan 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:59545/publication/wu-2023-signal/</guid>
      <description>&lt;h3 id=&#34;abstract&#34;&gt;Abstract&lt;/h3&gt;
&lt;p&gt;Rolling element bearings (REBs) are the most frequent cause of machine breakdowns. Traditional methods for fault diagnosis in rolling bearings rely on feature extraction and signal processing techniques. However, these methods can be affected by the complexity of the underlying patterns and the need for expert knowledge during signal analysis. This paper proposes a novel signalto-image method in which the raw signal data are transformed into 2D images using continuous wavelet transform (CWT). This transformation enhances the features extracted from the raw data, allowing for further analysis and interpretation. Transformed images of both normal and faulty rolling bearings from the Case Western Reserve University (CWRU) dataset were used with deeplearning models from the ResNet family. They can automatically learn and identify patterns in raw vibration signals after continuous wavelet transform is used, eliminating the need for manual feature extraction. To further improve the training results, squeeze-and-excitation networks (SENets) were added to improve the process. By comparing results obtained from several models, we found that SE-ResNet152 has the best performance for REB fault diagnosis.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Towards an edu-metaverse of knowledge: Immersive exploration of university courses</title>
      <link>http://localhost:59545/publication/sin-2023-towards/</link>
      <pubDate>Sun, 01 Jan 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:59545/publication/sin-2023-towards/</guid>
      <description>&lt;h3 id=&#34;abstract&#34;&gt;Abstract&lt;/h3&gt;
&lt;p&gt;Metaverse, an alternative universe for play, work and interaction, has become a captivating topic for academia and industry in recent times. This opens the question on what a metaverse for education, or edu-metaverse, should look like. It is believed that this metaverse for learning should be grounded by a pedagogical theory. Particularly, we propose a constructivist metaverse learning theory with eight actionable principles to guide the edu-metaverse and its applications. With this metaverse learning theory, we further propose the framework for an edu-metaverse; it is essentially walkable yellow pages that connect knowledge. The core idea is to combine the structure of knowledge graphs and the immersion of virtual reality in order to facilitate association, exploration and engagement in learning. Our current prototype for this edu-metaverse vision, K-Cube VR, is also presented. We have tested K-Cube VR for the introduction of course topics to our students and the results indicate that our edu-metaverse framework benefits students by providing a focused environment and structured learning on the topics of a course, akin to a mind map. Overall, in this paper, we present an edu-metaverse design that is rooted in a constructivist pedagogy that already shows promising results from a pilot user study via our metaverse prototype.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Design of Intelligent Multi-layer Three-dimensional Bicycle Parking Garage</title>
      <link>http://localhost:59545/publication/wang-2020-design/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:59545/publication/wang-2020-design/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
